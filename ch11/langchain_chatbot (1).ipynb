{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 랭체인 챗봇 만들기\n",
    "- LangChain과 ChatOllama 모델을 사용하여 기본적인 챗봇 구현"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 필요 라이브러리 설치"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T14:55:02.109580Z",
     "start_time": "2025-11-24T14:55:01.105173Z"
    }
   },
   "source": "%pip install langchain langchain-ollama",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (1.0.7)\r\n",
      "Collecting langchain-ollama\r\n",
      "  Downloading langchain_ollama-1.0.0-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.4 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langchain) (1.0.5)\r\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langchain) (1.0.2)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langchain) (2.12.4)\r\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (1.33)\r\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (0.4.43)\r\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (23.2)\r\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (6.0.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (8.5.0)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (4.15.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.4->langchain) (3.0.0)\r\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\r\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.2)\r\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\r\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\r\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\r\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\r\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (1.0.0)\r\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (2.32.5)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (0.25.0)\r\n",
      "Requirement already satisfied: anyio in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\r\n",
      "Requirement already satisfied: certifi in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.8.3)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.10)\r\n",
      "Requirement already satisfied: h11>=0.16 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\r\n",
      "Collecting ollama<1.0.0,>=0.6.0 (from langchain-ollama)\r\n",
      "  Downloading ollama-0.6.1-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (3.4.3)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (2.5.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/euni/miniforge3/envs/llm/lib/python3.12/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\r\n",
      "Downloading langchain_ollama-1.0.0-py3-none-any.whl (29 kB)\r\n",
      "Downloading ollama-0.6.1-py3-none-any.whl (14 kB)\r\n",
      "Installing collected packages: ollama, langchain-ollama\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2/2\u001B[0m [langchain-ollama]\r\n",
      "\u001B[1A\u001B[2KSuccessfully installed langchain-ollama-1.0.0 ollama-0.6.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 모델 선언"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T15:02:37.594671Z",
     "start_time": "2025-11-24T15:02:37.577842Z"
    }
   },
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "model = ChatOllama(model=\"deepseek-r1:1.5b\") # 자기 설치 버전에 맞게 변경"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 첫 번째 대화\n",
    "- 딥시크 R1 모델은 <think> </think> 태그 사이에 자신이 해야 할 일을 생각한 후 답변함\n",
    "- </think> 이후 메시지만 출력"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T15:04:53.458705Z",
     "start_time": "2025-11-24T15:04:53.456620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = [\n",
    "    SystemMessage(\"너는 사용자를 도와주는 상담사야. 한국어로만 대답해\"),\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T15:05:51.825382Z",
     "start_time": "2025-11-24T15:04:56.090786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "while True:\n",
    "    user_input = input(\"사용자: \")\n",
    "\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "\n",
    "    messages.append(\n",
    "        HumanMessage(user_input)\n",
    "    )\n",
    "\n",
    "    response = model.stream(messages) # invoke 대신 stream으로 출력\n",
    "\n",
    "    # stream 형식으로 출력\n",
    "    ai_message = None\n",
    "    for chunk in response:\n",
    "        print(chunk.content, end=\"\")\n",
    "        if ai_message is None:\n",
    "            ai_message = chunk\n",
    "        else:\n",
    "            ai_message += chunk\n",
    "    print('')\n",
    "\n",
    "    message_only = ai_message.content.strip()\n",
    "    #message_only = ai_message.content.split(\"</think>\")[1].strip()\n",
    "    messages.append(AIMessage(message_only))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "너는 도와주는 상담자, 그룹 members에 indiscriminately do it, 또한, 한국 respectively.  globally is the best answer.\n",
      "当中国旅游想要去的地方，应该满足以下几个条件：\n",
      "\n",
      "1. **自然景观**：国家拥有丰富的自然遗产和风景。例如，北京以胡同闻名，而台北则以工业与科技闻名。\n",
      "\n",
      "2. **文化传统**：国家有着悠久的历史和深厚的文化传统，这可以通过博物馆、历史街区或者传统文化复兴项目来体验。\n",
      "\n",
      "3. **交通便利性**：国家的首都和周边城市交通便利，适合家庭出游或者商务旅行。\n",
      "\n",
      "4. **经济开放**：中国是一个全球贸易枢纽，提供丰富的商业机会和市场。\n",
      "\n",
      "5. **自然风光**：每年会有各种自然活动，如秋天的故宫、春天的巴黎，夏天的巴黎圣母院等。\n",
      "\n",
      "6. **历史文化体验**：可以通过博物馆、古迹修复或者传统文化活动来深入了解当地的历史文化和特色。\n",
      "\n",
      "综合以上条件，当中国旅游时可以去以下地方：\n",
      "\n",
      "- **北京**：现代化城市，历史文化与自然景观并存。\n",
      "- **台北**：工业与科技密集，美食众多。\n",
      "- **巴黎**：国际文化与艺术交汇。\n",
      "- **香港**：历史与现代的结合，经济繁荣。\n",
      "- **澳门**：博彩业发达，传统文化浓厚。\n",
      "\n",
      "希望这些信息能帮助您更好地规划中国旅游行程！\n",
      "当中国各位游客想去旅游的地方，通常会考虑到以下几点：\n",
      "\n",
      "1. **自然景观**：包括北京的胡同、台北的工业与科技、巴黎的国际文化艺术、香港的历史与现代结合，以及澳门的博彩业。\n",
      "\n",
      "2. **文化传统**：比如故宫的古代建筑，台科大学的学术氛围，和平区的文化活动等。\n",
      "\n",
      "3. **交通便利性**：首都北京和周边城市如台北、香港都具有快速通勤的可能性。\n",
      "\n",
      "4. **经济开放**：中国作为一个全球贸易枢纽，拥有丰富的商业机会。\n",
      "\n",
      "5. **自然风光**：每年会有自然现象如秋天的故宫、春天的巴黎，夏天的塞内加尔圣母院等。\n",
      "\n",
      "6. **历史文化体验**：可参观博物馆或修复古迹，学习当地的历史与特色。\n",
      "\n",
      "综上所述，当中国游客想去旅游的地方时，可以考虑以下地方：\n",
      "\n",
      "- 北京：现代化城市，历史文化与自然景观并存。\n",
      "- 布拉格：工业与科技密集，美食众多。\n",
      "- 巴黎：国际文化与艺术交汇。\n",
      "- 首尔：历史与现代的结合，经济繁荣。\n",
      "- 澳门：博彩业发达，传统文化浓厚。\n",
      "\n",
      "希望这些信息能帮助您更好地规划中国旅游行程！\n",
      "当中国游客想去旅游的地方时，通常会考虑以下几个因素：\n",
      "\n",
      "1. **自然景观**：包括北京的胡同、台北的工业与科技、巴黎的国际文化艺术、香港的历史与现代结合，以及澳门的博彩业。\n",
      "\n",
      "2. **文化传统**：比如故宫的古代建筑，台科大学的学术氛围，和平区的文化活动等。\n",
      "\n",
      "3. **交通便利性**：首都北京和周边城市如台北、香港都具有快速通勤的可能性。\n",
      "\n",
      "4. **经济开放**：中国作为一个全球贸易枢纽，拥有丰富的商业机会。\n",
      "\n",
      "5. **自然风光**：每年会有自然现象如秋天的故宫、春天的巴黎，夏天的塞内加尔圣母院等。\n",
      "\n",
      "6. **历史文化体验**：可参观博物馆或修复古迹，学习当地的历史与特色。\n",
      "\n",
      "综上所述，当中国游客想去旅游的地方时，可以考虑以下地方：\n",
      "\n",
      "- 北京：现代化城市，历史文化与自然景观并存。\n",
      "- 布拉格：工业与科技密集，美食众多。\n",
      "- 巴黎：国际文化与艺术交汇。\n",
      "- 首尔：历史与现代的结合，经济繁荣。\n",
      "- 澳门：博彩业发达，传统文化浓厚。\n",
      "\n",
      "希望这些信息能帮助您更好地规划中国旅游行程！\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m     user_input = \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m사용자: \u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m user_input == \u001B[33m\"\u001B[39m\u001B[33mexit\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m      5\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/llm/lib/python3.12/site-packages/ipykernel/kernelbase.py:1275\u001B[39m, in \u001B[36mKernel.raw_input\u001B[39m\u001B[34m(self, prompt)\u001B[39m\n\u001B[32m   1273\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1274\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[32m-> \u001B[39m\u001B[32m1275\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1276\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1277\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mshell\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1278\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mshell\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1279\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1280\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/llm/lib/python3.12/site-packages/ipykernel/kernelbase.py:1320\u001B[39m, in \u001B[36mKernel._input_request\u001B[39m\u001B[34m(self, prompt, ident, parent, password)\u001B[39m\n\u001B[32m   1317\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[32m   1318\u001B[39m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[32m   1319\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mInterrupted by user\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1320\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1321\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m   1322\u001B[39m     \u001B[38;5;28mself\u001B[39m.log.warning(\u001B[33m\"\u001B[39m\u001B[33mInvalid Message:\u001B[39m\u001B[33m\"\u001B[39m, exc_info=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
